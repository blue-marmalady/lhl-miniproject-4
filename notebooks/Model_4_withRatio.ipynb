{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building a Predictive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\k_mah\\Documents\\miniproject4-master\\data\\cleanloans.csv')\n",
    "df.head()\n",
    "df = df.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to have the Loan Status as binary when we get to the models, so let's do that first\n",
    "df['Loan_Status'] = df.Loan_Status.replace(to_replace=['N', 'Y'], value=[0, 1])\n",
    "y = df['Loan_Status']\n",
    "df = df.drop(columns='Loan_Status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And then, let's convert the rest of our variables to dummies so we can use standard scalar\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Now we can assign the rest of the dataframe as the training variables\n",
    "X = df\n",
    "\n",
    "#And split our test and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale and do PCA\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X_train_scaled)\n",
    "X_train_pca = pca.transform(X_train_scaled)\n",
    "\n",
    "# make sure to do same pre-processing to testing data as well.\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6638655462184874\n",
      "0.7047619047619048\n",
      "0.891566265060241\n",
      "[[ 5 31]\n",
      " [ 9 74]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "rdf = RandomForestClassifier()\n",
    "rdf.fit(X_train_pca, y_train)\n",
    "rdf_pred = rdf.predict(X_test_pca)\n",
    "\n",
    "print(accuracy_score(y_test,rdf_pred))\n",
    "print(precision_score(y_test, rdf_pred))\n",
    "print(recall_score(y_test, rdf_pred))\n",
    "print(confusion_matrix(y_test, rdf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try paramater grid search to improve the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "The grid score: 0.8403361344537815\n"
     ]
    }
   ],
   "source": [
    "params1 = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 20]\n",
    "}\n",
    "\n",
    "grid1 = GridSearchCV(estimator=rdf, param_grid=params1, verbose=1).fit(X_train, y_train)\n",
    "print(f'The grid score: {grid1.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6638655462184874\n",
      "0.7047619047619048\n",
      "0.891566265060241\n",
      "[[ 5 31]\n",
      " [ 9 74]]\n"
     ]
    }
   ],
   "source": [
    "xgbc = XGBClassifier()\n",
    "xgbc.fit(X_train_pca, y_train)\n",
    "xgbc_pred = rdf.predict(X_test_pca)\n",
    "\n",
    "print(accuracy_score(y_test,xgbc_pred))\n",
    "print(precision_score(y_test, xgbc_pred))\n",
    "print(recall_score(y_test, xgbc_pred))\n",
    "print(confusion_matrix(y_test, xgbc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try paramater grid search to improve the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "The grid score: 0.8319327731092437\n"
     ]
    }
   ],
   "source": [
    "params2 = {\n",
    "    'booster': ['gbtree', 'dart'],\n",
    "    'max_depth': [5, 10, 20]\n",
    "}\n",
    "\n",
    "grid2 = GridSearchCV(estimator=xgbc, param_grid=params1, verbose=1).fit(X_train, y_train)\n",
    "print(f'The grid score: {grid2.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8319327731092437\n",
      "0.8058252427184466\n",
      "1.0\n",
      "[[16 20]\n",
      " [ 0 83]]\n"
     ]
    }
   ],
   "source": [
    "lsvc = LinearSVC(random_state=0, C=0.01, max_iter = 6000).fit(X_train_scaled,y_train)\n",
    "\n",
    "svc_pred = lsvc.predict(X_test_scaled)\n",
    "\n",
    "print(accuracy_score(y_test,svc_pred))\n",
    "print(precision_score(y_test, svc_pred))\n",
    "print(recall_score(y_test, svc_pred))\n",
    "print(confusion_matrix(y_test, svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try paramater grid search to improve the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "The grid score: 0.8403361344537815\n"
     ]
    }
   ],
   "source": [
    "params3 = {\n",
    "                'kernel' : ['linear', 'rbf', 'poly'],\n",
    "                'gamma' : [0.1, 1, 10, 100],\n",
    "                'C' : [0.1, 1, 10, 100, 1000],\n",
    "}\n",
    "\n",
    "grid3 = GridSearchCV(estimator=rdf, param_grid=params1, verbose=1).fit(X_train, y_train)\n",
    "print(f'The grid score: {grid3.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c0d89b5f63db5632f8f002f79a09b21938afa1ab48b28293f9c2c3a2f99e497b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
